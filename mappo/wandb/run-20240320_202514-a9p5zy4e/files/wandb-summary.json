{"value_loss": 0.005770946945995092, "policy_loss": 0.0038549329930295546, "dist_entropy": 1.0676963965098063, "actor_grad_norm": 0.21373753249645233, "critic_grad_norm": 0.16113434731960297, "ratio": 0.9893900156021118, "test_score": -2.000000000000001, "episode_rewards": -1.999999761581421, "_timestamp": 1710934954.4596553, "_runtime": 1039.6028492450714, "_step": 3931}
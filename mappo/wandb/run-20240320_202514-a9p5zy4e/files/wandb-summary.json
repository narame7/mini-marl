{"value_loss": 0.005281174120803674, "policy_loss": -0.011470603321989377, "dist_entropy": 1.0775173823038737, "actor_grad_norm": 0.5672105550765991, "critic_grad_norm": 0.35301727056503296, "ratio": 0.9971299767494202, "test_score": -2.000000000000001, "episode_rewards": -1.999999761581421, "_timestamp": 1710934488.4274497, "_runtime": 573.5706436634064, "_step": 2189}